---
layout: post
title: 'TIL #43'
category:
  - Today I Learned
tags:
  - NGINX
  - Reverse Proxy
  - Load Balancing
date: '2023-08-21T20:00:00+09:00'
---

## Reverse Proxy

Nginx는 사용자의 요청을 받아 특정 웹서버로 전달한 다음 그에 대한 응답을 사용자에게 다시 전송해준다. 이와 같이 외부에서 사용자의 요청을 받아 내부 서버가 제공하는 서비스 접근할 때, Proxy 서버(_중계 서버, Nginx_)를 먼저 거쳐 내부 서버로 들어오는 방식을 *리버스 프록시(Reverse Proxy)*라고 한다. 여기서 *프록시(Proxy)*란 대리라는 의미로, 정보를 대신 전달해주는 주체라고 생각하면 된다.

```nginx
upstream node_upstream {
	server node:5000;
}

location / {
	proxy_pass http://node_upstream; # Forwarding
}
```

예시 코드에서의 node는 내가 Docker Compose를 사용했기에, 이를 통해 생성된 Node.js 서버의 서비스 이름이다. 위의 proxy*pass는 들어온 요청을 어디로 포워딩(\_forwarding*)할지 지정해준다.

### 장점

- **보안** : 외부 사용자는 실제 내부망에 있는 서버의 존재를 모른다. 모든 접속은 Reverse Proxy 서버에게 들어오며, Reverse Proxy는 요청에 맵핑되는 내부 서버의 정보를 알고 요청을 넘겨준다. 따라서 내부 서버의 정보를 외부로부터 숨길 수 있다.
- **로드 밸런싱** : Proxy 서버가 내부 서버의 정보를 알고 있으므로 로드밸런싱을 통해 부하 여부에 따라 요청을 분배 할 수 있다.

## 로드 밸런싱(Load Balancing)

![Load Balancing](https://user-images.githubusercontent.com/50273712/140634974-ff0038af-e9b6-48ef-a565-1d454f32377c.png)

쏟아지는 트래픽을 여러 대의 서버로 분산시켜주는 기술이 없다면 한 곳의 서버에 모든 트래픽이 몰리는 상황이 발생할 것이다. 이때 필요한 기술이 바로 로드 밸런싱이다.

로드 밸런싱이란 말 그대로 서버가 처리해야 할 업무 혹은 요청(_Load_)을 여러 대의 서버로 나누어(_Balancing_) 처리하는 것을 의미한다. **한 대의 서버로 부하가 집중되지 않도록 트래픽을 관리해 각각의 서버가 최적의 퍼포먼스를 보일 수 있도록 하는 것이 목적**이다.
서비스의 규모가 커지고, 이용자 수가 늘어나게 되면 기존의 서버만으로는 원활한 서비스 동작이 불가능하게 되고, 이에 대처할 수 있는 방법은 크게 두 가지로 나뉜다.

- 기존의 서버 성능을 확장하는 Scale-up 방식
- 기존의 서버와 동일하거나 낮은 성능의 서버를 증설하는 Scale-out 방식

⠀이때 Scale-out 방식을 통해 증가한 트래픽에 대처하기로 했다면, 여러 대의 서버로 트래픽을 균등하게 분산해주는 로드 밸런싱이 반드시 필요하다.

### 기법

서버의 능력을 고려하여 분배해야 하기 때문에 서버의 상황에 맞춰 적절한 방법을 선택해야 한다.

- **라운드로빈 방식(Round Robin Method)**
  서버에 들어온 요청을 순서대로 돌아가며 배정하는 방식이다. 클라이언트의 요청을 순서대로 분배하기 때문에 여러 대의 서버가 동일한 스펙을 갖고 있고, 서버와의 연결(세션)이 오래 지속되지 않는 경우에 활용하기 적합하다.

- **가중 라운드로빈 방식(Weighted Round Robin Method)**
  각각의 서버마다 가중치를 매기고 가중치가 높은 서버에 클라이언트 요청을 우선적으로 배분한다. 주로 서버의 트래픽 처리 능력이 상이한 경우 사용되는 부하 분산 방식이다. 예를 들어 A라는 서버가 5라는 가중치를 갖고 B라는 서버가 2라는 가중치를 갖는다면, 로드 밸런서는 라운드로빈 방식으로 A 서버에 5개 B 서버에 2개의 요청을 전달한다.

- **IP 해시 방식(IP Hash Method)**
  클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리하는 방식이다. 사용자의 IP를 해싱해(_Hashing, 임의의 길이를 지닌 데이터를 고정된 길이의 데이터로 매핑하는 것, 또는 그러한 함수_) 로드를 분배하기 때문에 사용자가 항상 동일한 서버로 연결되는 것을 보장한다.

- **최소 연결 방식(Least Connection Method)**
  요청이 들어온 시점에 가장 적은 연결상태를 보이는 서버에 우선적으로 트래픽을 배분한다. 자주 세션이 길어지거나, 서버에 분배된 트래픽들이 일정하지 않은 경우에 적합한 방식이다.

- **최소 응답 시간 방식(Least Response Time Method)**
  서버의 현재 연결 상태와 응답 시간(_Response Time, 서버에 요청을 보내고 최초 응답을 받을 때까지 소요되는 시간_)을 모두 고려하여 트래픽을 배분한다. 가장 적은 연결 상태와 가장 짧은 응답 시간을 보이는 서버에 우선적으로 로드를 배분하는 방식이다.

---

### Reference

- [\[Nginx\] 리버스 프록시\(Reverse Proxy\) 개념 및 사용법](https://narup.tistory.com/238)
- [NGINX Reverse Proxy](https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/)
- [Nginx Reverse Proxy 사용하기](https://medium.com/sjk5766/nginx-reverse-proxy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-e11e18fcf843)
- [로드 밸런싱에 대해 알아보자!](https://tecoble.techcourse.co.kr/post/2021-11-07-load-balancing/)
